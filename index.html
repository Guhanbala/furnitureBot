<!DOCTYPE html>
<html>
<head>
  <title>V Furnish</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {font-family:Arial; text-align:center; padding:50px; background:#fff8e7}
    button {padding:20px 40px; font-size:22px; background:#ff4500; color:white; border:none; border-radius:15px; cursor:pointer}
    #text {margin-top:30px; font-size:24px; color:#d4380d; font-weight:bold}
  </style>
</head>
<body>
  <h1>V Furnish Voice Assistant</h1>
  <button id="rec">SPEAK NOW</button>
  <div id="text">Listening...</div>

  <script type="module">
    // HIDDEN KEY FROM GITHUB SECRETS
    const OPENAI_KEY = "<%= process.env.OPENAI_KEY %>";

    const button = document.getElementById('rec');
    const output = document.getElementById('text');
    let rec, chunks = [];

    button.onclick = async () => {
      output.textContent = "Recording 4 sec...";
      chunks = [];
      const stream = await navigator.mediaDevices.getUserMedia({audio:true});
      rec = new MediaRecorder(stream);
      rec.ondataavailable = e => chunks.push(e.data);
      rec.onstop = () => sendToWhisper();
      rec.start();
      setTimeout(() => rec.stop(), 4000);
    };

    async function sendToWhisper() {
      output.textContent = "Sending to cloud...";
      const blob = new Blob(chunks, {type: 'audio/webm'});
      const form = new FormData();
      form.append('file', blob, 'voice.webm');
      form.append('model', 'whisper-1');

      const res = await fetch('https://api.openai.com/v1/audio/transcriptions', {
        method: 'POST',
        headers: {
          'Authorization': 'Bearer ' + OPENAI_KEY
        },
        body: form
      });

      const data = await res.json();
      console.log(data);
      output.textContent = "You said: " + (data.text || "nothing â€” try again!");
    }
  </script>
</body>
</html>
