<!DOCTYPE html>
<html>
<head>
  <title>V Furnish</title>
  <style>
    body {font-family:Arial; text-align:center; padding:50px; background:#fff8e7}
    button {padding:20px 40px; font-size:22px; background:#ff4500; color:white; border:none; border-radius:15px}
    #text {margin-top:30px; font-size:24px; color:#d4380d; font-weight:bold}
  </style>
</head>
<body>
  <h1>V Furnish Voice Assistant</h1>
  <button id="rec">SPEAK NOW</button>
  <div id="text">ðŸ‘‚ Listening...</div>

  <script>
    const button = document.getElementById('rec');
    const output = document.getElementById('text');
    let rec, chunks = [];

    button.onclick = async () => {
      output.textContent = "Recording 4 seconds...";
      chunks = [];
      const stream = await navigator.mediaDevices.getUserMedia({audio:true});
      rec = new MediaRecorder(stream);
      rec.ondataavailable = e => chunks.push(e.data);
      rec.onstop = () => sendToWhisper();
      rec.start();
      setTimeout(() => rec.stop(), 4000);
    };

    async function sendToWhisper() {
      output.textContent = "Sending to cloud...";
      const blob = new Blob(chunks, {type: 'audio/webm'});
      const form = new FormData();
      form.append('file', blob, 'voice.webm');
      form.append('model', 'whisper-1');

      const res = await fetch('https://api.openai.com/v1/audio/transcriptions', {
        method: 'POST',
        headers: { 'Authorization': 'Bearer sk-proj-wqaw2UlkaXqXynoxVida6K1lhJKcSpG_LHhWoyeRx5fH31fiJ0MfIvlzzdesXSmacA2NctuHJgT3BlbkFJo8YN04Q0JPaEtT0AVUzGI2Udq6nea1N7Bw8agOLhGZjtWAt-pvjBSvGvQUGu88yATnWKjkvCEAE' },
        body: form
      });
      const json = await res.json();
      output.textContent = "You said: " + (json.text || "nothing â€” try again!");
    }
  </script>
</body>
</html>
